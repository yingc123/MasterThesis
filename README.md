# MasterThesis
Binary Mask Generation in 3D+T Microscopy Images using Convolutional Neural Networks and Temporal Smoothness Constraints

Abstract:
In the past few years, deep learning-based methods and particularly convolutional neural networks (CNNs) have shown remarkable results on various kinds of computer vision tasks like object detection, semantic segmentation, instance segmentation and tracking. To improve the results of automatic segmentation and tracking methods in noisy 3D+t image data of developing embryos, an accurate specification of the region of interest to be analyzed is of utmost importance. This can help, for instance, to constrain automatic algorithms to the correct image region or for data size reduction by discarding unimportant background information. The aim of this Masterâ€™s thesis is to develop new methods for the generation tight binary masks that can be used to identify the regions of interest and to accurately separate the background from the foreground regions. This should also work for hollow specimens, where an outer and an inner surface area needs to be determined. This method should replace the currently manually performed masking steps and should allow to analyze even terabyte-scale data sets automatically, by providing a good selection of where to apply automatic segmentation and tracking methods. The masks should also be smoothly changing over time, to be able to quantitatively compare adjacent image frames without large variations in the binary masks as frequently observed when manually masking the images. This will be accomplished via customized semantic segmentation networks, to emphasize the interfaces of interior vs. exterior and using the resulting probability maps to identify the inner and outer surface of the embryos. For instance, a combination with classical methods like level sets segmentation or surface evolution may help to tightly identify the respective interfaces. By defining the optimality criteria for surface fitting for overlapping frames (e.g., using the previous, the current and the next frame at once), smooth transitions between the frames should be achievable. A proof-of-concept prototype will first be conceived in 2D and will then be extended to 3D, if promising results are obtained. The data basis is formed by 3D+t light-sheet and confocal microscopy images of Drosophila melanogaster (fruit fly), Arabidopsis thaliana (thale cress) and Danio rerio (zebrafish), where the plasma membranes of all cells were labeled with a fluorescent marker.

We proposed a method combining convolution neural network and spatiotemporal smoothing techniques used for semantic segmentation of the 4D Drosophila and Arabidopsis embryos datasets. The method, 3D U-net +STP, segments the background from the foreground regions for a temporal sequence of volumetric images, it can automatically analyze large scale datasets and replace the currently manually performed masking steps. Furthermore, the generated masks of 3D U-net +STP are smoothly changing in both the spatial and temporal domains.

![3D U-net + STP (spatiotemporal postprocessing)](https://github.com/yingc123/MasterThesis/blob/master/3dunet_smoothing.png)
